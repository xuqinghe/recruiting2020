矩阵乘法加速器的设计框架：https://cloud.tencent.com/developer/article/1601127

计算单元 缓存（SRAM，读写快，容量小） 内存（DDR，读写慢，容量大）

DDR==SRAM==Execution Unit

特定的加速器可以设计数量巨大的计算单元，DDR的提升是有限的。

设计目标之一在于优化数据访问，降低DDR的读写带宽。

假设：总缓存大小为M

存储矩阵（A,B,C） 的缓存空间大小为（Ma,Mb,Mc）

矩阵乘法加速器的设计目的一般是为了加速大规模的矩阵乘法计算
假设（A,B,C） 的大小为（Sa，Sb，Sc）均远大于M

计算过程中，每次只能缓存一部分数据，完成子矩阵（Asub，Bsub，Csub）的计算

是否有冗余数据浪费存储和带宽，因此（Asub，Bsub，Csub）应能够完成一组矩阵计算
ps sq pq  之前是 mk kn mn

为了完成矩阵计算，从DDR到SRAM的总数据读写为
Dsize = n/q * Sa + m/p * Sb + 2 * Sc

optimization problem:
min:mnk/q + mnk/p + 2mn
sub.to: p*s + s*q +p*q <= M
p >0 , s >0 , q>0

min:1/q +1/p 
sub.to: p*s + s*q +p*q <= M
p >0 , s >0 , q>0

when s = 1, p = 1 = sqrt M +1 -1

结论：若要设计一个带宽优化的乘法器，应该尽可能的将缓存用于存储Csub

每次计算的子矩阵为：C pq = A p*1 + B 1*q

Telsa的FSD的设计和上述讨论结果是一致的，只不过FSD的SRAM对应了上述的DDR，Register对应了上述的SRAM，对应的FSD的设计实际上是以降低SRAM-Register之间的读写为目的进行优化的。

3、计算优化的矩阵乘法加速器设计： 

上述计算并行度最高为p*q（每个周期完成p*q个乘法）

而为完成一次计算，需要从缓存里读取（p+q+q*p）个数据送入到计算阵列中。因此一次读/写的数据位宽宽度极高，并随着并行度的增长，数据位宽线性增长。

数据位宽的问题主要存在Csub上，为了解决这一问题，Tesla FSD采用了移位的方式，在计算完成后，将计算结果依次写回到SRAM中。

如果涉及目的在于计算阵列和缓存之间的优化，参考第二节的设计思路，在一定并行度上，希望尽可能降低缓存的读写带宽，优化目标可以表示为

min：x*y+y*z+x*z
sub.to： x*y*z = P
x>0, y>0, z>0

其中P代表计算阵列的并行度，求解得当x=y=z=sqrt[3]P时，此时设计的计算阵列对缓存的访问可以尽可能的低。

华为的达芬奇架构中计算阵列的设计和上述讨论是一致的，达芬奇中的CUBE Core是一个 16*16*16 的MAC阵列，可以完成 16*16 = 16*16 x 16*16 的














